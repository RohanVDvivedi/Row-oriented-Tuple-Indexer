** PICKED TASKS
 * refactor and change data_access_methods to page_access_methods
 * make in_memory_data_store use rwlock
 * make read_only_page_layout header in tuple store
 * make child_page_id non nullable, to save 1 bit of memory
 * calculate precisely whether a tuple can be inserted into a bplus tree in bpttd
 * make page_access_methods and allow only modifying a page thtrough it
 * allow page_access_methods (with a context) to also enable locking only tuples on the page
 * build a struct persistent_page that holds page, page_id and page_size, and pass that around instead
 * allow transaction_context to be passed arround and this is a input parameter to page_access_methods and page_modification_methods
 * implement locked_pages_stack using value_arraylist

** UTILITY AND REFACTORING
 * segregate insert and delete into 2 functions, to reuse code, provide implementations to split_insert function call and merge_if_possible
 * locked_page_info may have READ_LOCKED/WRITE_LOCKED and MODIFIED/UN_MODIFIED bit fields to support the above task of segregation
 * add a flag as a parameter "fail_on_duplicate_key", that decides to fail an insert if a record being inserted has a duplicate key, else allow duplicates
 * build stacked iterator using locked_pages_stack, this can be used to iterate over all the tuples in the b+tree including the interior page - index tuples
 * utility function to delete an index tuple from an index page

** UPDATE FUNCTIONALITY
 * implement update which split or merges depending on the size of the record being updated, (and does neither for fixed length records or if new record and old record are of same size)
 * update by key (updates the last 1) or update by record (updates an exact match record -> here we will already know if it will be a merge or a split)

** ADDITIONAL DELETE FUNCTIONALITY
 * implement delete range, deleting an entire sub tree if it falls into the range (parameter key1 and key2, (key1 <= key2) and flags that suggest whether key1 and key2 are inclusive or not)
 * implement delete record, to delete a specific record from b+tree

** OPTIMIZATION
 * implement redistribute keys functions for fixed length index_def, this will reduce propogation of merges, this task can be delayed to be done at the end
 * see how this can be accomodated in the delete and update functions available at that point in future

** NECESSARY BUT DELAYED UNTIL ACTUAL REQUIREMENTS ARE FULFILLED
 * implement an error handling strategy to check the was_modified parameter, in in-memory-data-store, and exit with error, if the page was modified and was_modified was not set OR if page was not modified and was_modified was set
 * go through the project and implemnt better error handling for failures of malloc and data_access_methods (now page_access_methods)
 * implement throwing errors appropriately, upon failures from dam_p
 * write multi threaded test cases to insert a large csv in to b+tree, measure performance difference

** OTHER DATABASE DATASTRUCTURE TASKS
 * linked_page_list push_tuple_at_head, push_tuple_at_tail, get_head_tuple, get_tail_tuple, pop_tuple_from_head and pop_tuple_from_tail as its access functions and an iterator from head to tail or the other way around. it will be a doubly linkedlist of tuples
 * all inserts to linked_page_list have a flag to PRESERVE_ROOT_PAGE_ID
 * hash_table, a linux page table like hashtable where each bucket points a linked_page_list
 * sort that can be called on a linked_page_list or a hash_table
 * building a b+tree using a sorted linked_page_list, layer by layer - think how to get it done without having first index entries
