** PICKED TASKS

DAM FEATURES
 * dam add functionality (Still think if you need this, with current hashtable design we have, we do not need this)
  * uint64_t allocate_contiguous_pages(uint64_t page_count), returning first page id of the allocated pages.
  * free_contiguous_pages(uint64_t first_page_id, uint64_t page_count), instead of free_page -> to free n contiguous pages.

** OTHER DATABASE DATASTRUCTURE TASKS (VERY IMPORTANT FOR FUTURE OF PROJECT)
 * bplus_tree bulk loading
   * bulk loading to accept bpttd_p, dam_p and pmm_p and allocate root page first
   * api to accept accept records, tuple by tuple
   * on build_call, generate interior pages
   * for building ith level of interior page, from the i-1th level, we copy the 1st row from the page with page id of the page, we will use the least_keys_page_id to link the level of the interior pages. for building tuple for iterior page level 1, we will use the suffix compression also to build the index tuple, while for other levels we will only use the same index tuple as in the first row of the interior page.
   * in the last pass, we will revisit all the interior pages using dfs and move the first row's page_id to least_keys_page_id and discard the first row.
 * a page_table that maps a 64 bit integer to a page_id
   * It is structured as a tree, starting with level 0, and then increasing towards root, like bplus tree
   * root always stays at the same page_id and is never freed, unless a destroy is called, hence the page_table capacity is atleast E (E being the number of page_id entries that can accomodate 1 page)
   * each page contains list of page_ids, each of page_id_width, pointing to another page_table page (when its level > 0) OR something else (when its level = 0), all pages are identical.
   * If there are E entries in each of the page, and if the root page has level = n, then the page table has E^(n+1) buckets.
   * If the root has only 1 entry at its first index, then the hash_table shrinks, by moving the contents of its new child to the root.
   * child pages are allocated as and when required, not upfront
   * If any page becomes all empty, then it is freed and an entry from its parent is discarded, shrinking the hash_table up the chain.
 * linked_page_list where you can iterate over the page over all its tuples, head remains at the same page_id, you can insert -> inserting always at the tail, top and pop -> returns the tail (previous element inserted) or the head (first element inserted)
   * this can work as both stack and queue
   * tuples are never moved, any page other than head page, can be discarded if it becomes empty
   * deletes to other tuples (other than head and tail) are allowed by updating them with NULL, using a writable iterator
   * a writable iterator can write to an existing slot if it is NULL and if that tuple fits on the page
 * hash_table, a page_table points a linked_page_list
   * with (duplicate keys allowed)
   * when a linked_page_list becomes all empty, then linked_page_list is destroyed and NULL_PAGE_ID is written to page_table
     * we let the page_table mnage shrinking, keeping the root_page at fixed page_id
 * linked_page_list push_tuple_at_head, push_tuple_at_tail, get_head_tuple, get_tail_tuple, pop_tuple_from_head and pop_tuple_from_tail as its access functions and an iterator from head to tail or the other way around. it will be a doubly linkedlist of tuples
 * all inserts to linked_page_list have a flag to PRESERVE_ROOT_PAGE_ID
 * sort
   * it accepts record in the bplus_tree_bulkloading like interface
   * puts tuples in a page, sorts them and inserts it into a page_table
   * it will then merge adjacent runs until the page_table contains only 1 entry
 * Rtree will be supported
   * very similar to b+tree, n dimensional data can be inserted, deleted, no least_keys_page_id required
   * splits and merges happen according to the minimal increase in interior node areas
   * may need to lock all pages till leaf to ensure no new insertions to the same range are possible
   * inserts and deletes can release page locks if it is deemed that split and merge would not propogate up the tree
   * accomodate any tuple that is atleast half the size of the leaf page, and interior page tuples would be fixed width with non NULL elements
   * keys will have a even count and all of numeral types, for ith dimension lower bound would be 2*i th key element and 2*i+1 will be upper bound, up to d dimentions (0 <= i < 2*d).
 * think about implementing more data structures like T-tree, Patricia Trie, etc

** OPTIMIZATION (THIS MAY NEVER MAKE IT TO THE PROJECT)
 * implement redistribute keys functions for fixed length index_def, this will reduce propogation of merges, this task can be delayed to be done at the end
 * prefix key compression -> store prefix compression for var_strings (for internal nodes only), working in the following ways
    0  ->  "ABCD"            "ABCD"
    1  ->  "ABDEF"           "2DEF"
    2  ->  "ABDFG"           "3FG"
    3  ->  "ABDH"       ->   "3H"
    4  ->  "ADEA"            "1DEA"
    5  ->  "ADEF"            "3F"
    6  ->  "ADEGH"           "3GH"
    each var string except the first 1 stores itself OR its difference from the (same column) var string in the previous row
    the difference is stores as a number (suggesting the common characters from the previous var string) followed by the characters that are different.

    to differentiate the prefix number from the other characters, we will always store them in element_def's size_specifier_prefix_size number of bytes after an invalid unicode character "0xFF 0xFF".

    Algorithm to construct the string at ith index
    compute the length of the var string, that is 3 + "G" 1 + "H" 1 = 5
    bytes_to_read = 5 stack = ""
    now start iterating until bytes_to_read > 0
    i == 6 -> bytes_to_read = 3 stack = "HG"
    i == 5 -> bytes_to_read = 3 stack = "HG"
    i == 4 -> bytes_to_read = 1 stack = "HGED"
    i == 3 -> bytes_to_read = 1 stack = "HGED"
    i == 2 -> bytes_to_read = 1 stack = "HGED"
    i == 1 -> bytes_to_read = 1 stack = "HGED"
    i == 0 -> bytes_to_read = 0 stack = "HGEDA" -> reverse "ADEGH"

    stack = ""
    bytes_to_read = 5
    i = 6
    while(bytes_to_read > 0)
    {
      common_char_count, rest_of_string = get_column_from_ith_row(i);
      new_bytes_to_read = min(bytes_to_read, common_char_count);
      if(new_bytes_to_read > bytes_to_read)
      {
        for(int i = (new_bytes_to_read - bytes_to_read) - 1; i >= 0; i--)
          stack.push(rest_of_string[i]);
      }
      bytes_to_read = new_bytes_to_read;
    }
    return stack.reverse();

* think about future project (THIS WILL BE PROJECTS THAT WILL DEPEND ON THIS PROJECT)
 * think about how to do undo and redo logging
 * logical logging with physiological logging will allow us higher concurrency
 * mini transactions like that innodb can generate very large log records, which we may not want in memory
   * clubbing all physiological logs for a logical operation into a single buffer and log them only upon completion (with strict 2pl on the latches), can use large amount of memory for log buffer, but you can easily redo and undo it, it is never undone physiologically, only logically
 * How about we use logical mini transaction redo, composed of physiological logs, now we do physiological undo when logical operation is incomplete, and logical undo for other operations above. we may have to undo and undo in this case
