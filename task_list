** PICKED TASKS

B_PLUS_TREE BUG fix
 * current suffix_truncation logic in bplus_tree_leaf_page_util.c is buggy and is so turned off, implement correct logic all over again
 * need to fix partial key searches, not finding all the necessary keys
   * for this test with KEY_SEX_EMAIL and DESC, ASC sort ordering
   * write go_prceeding_function using key functionality, as a second function for find and use it with LESSER_THAN and GREATER_THAN_EQUALS find calls

* linked_page_list a doubly circular linkedlist of pages with tuple on them
  * struct linked_page_list_iterator
    {
      // current state of linked_page_list
      linked_page_list_state state;

      union
      {
        // for EMPTY_SINGULAR_HEAD_LINKED_PAGE_LIST and SINGULAR_HEAD_LINKED_PAGE_LIST
        struct
        {
          persistent_page head_page;
          uint32_t curr_tuple_index;
        };
        // for DUAL_NODE_LINKED_PAGE_LIST
        struct
        {
          persistent_page dual_node_pages[2]; // head page at index 0, and tail page is at index 1
          uint32_t curr_page_index;
          uint32_t curr_tuple_index;
        };
        // for MULTI_NODE_LINKED_PAGE_LIST
        struct
        {
          persistent_page curr_page;
          uint32_t curr_tuple_index;
        };
      };

      // head_page_id never changes
      uint64_t head_page_id;

      const linked_page_list_tuple_defs* lpltd_p;
      const page_access_methods* pam_p;
    }
    enum linked_page_list_state
    {
      EMPTY_SINGULAR_HEAD_LINKED_PAGE_LIST,
      SINGULAR_HEAD_LINKED_PAGE_LIST,
      DUAL_NODE_LINKED_PAGE_LIST,
      MULTI_NODE_LINKED_PAGE_LIST,
    };
    * implement functionality to
      * int is_writable_linked_page_list_iterator(const linked_page_list_iterator* bpi_p);
      * insert INSERT_BEFORE/INSERT_AFTER, EXPAND_TOWARDS_NEXT/EXPAND_TOWARDS_PREV -> when at head, you can only INSERT_TOWARDS_NEXT
      * remove GO_NEXT/GO_PREV
      * update
      * int next_linked_page_list_iterator(linked_page_list_iterator* lpli_p, const void* transaction_id, int* abort_error);
      * int prev_linked_page_list_iterator(linked_page_list_iterator* lpli_p, const void* transaction_id, int* abort_error);
      * merging happens while going next or prev
      * you need to handle logic to reposition the iterator after splits and merges
      * const void* get_tuple_linked_page_list_iterator(const linked_page_list_iterator* lpli_p);
    * it must support functionality like
    * this must work as both stack and queue
      * push_to_head_of_linked_page_list  - stack
      * pop_from_head_of_linked_page_list - stack queue
      * peek_head_of_linked_page_list     - stack queue
      * push_to_tail_of_linked_page_list  -       queue
    * add linked_page_list_iterator to public api headers

** OTHER DATABASE DATASTRUCTURE TASKS (VERY IMPORTANT FOR FUTURE OF PROJECT)
 * bplus_tree bulk loading
   * bulk loading to accept bpttd_p, dam_p and pmm_p and allocate root page first
   * api to accept accept records, tuple by tuple
   * on build_call, generate interior pages
   * for building ith level of interior page, from the i-1th level, we copy the 1st row from the page with page id of the page, we will use the least_keys_page_id to link the level of the interior pages. for building tuple for iterior page level 1, we will use the suffix compression also to build the index tuple, while for other levels we will only use the same index tuple as in the first row of the interior page.
   * in the last pass, we will revisit all the interior pages using dfs and move the first row's page_id to least_keys_page_id and discard the first row.
 * hash_table, a page_table points a linked_page_list
   * with (duplicate keys allowed)
   * when a linked_page_list becomes all empty, then linked_page_list is destroyed and NULL_PAGE_ID is written to page_table
     * we let the page_table mnage shrinking, keeping the root_page at fixed page_id
 * linked_page_list push_tuple_at_head, push_tuple_at_tail, get_head_tuple, get_tail_tuple, pop_tuple_from_head and pop_tuple_from_tail as its access functions and an iterator from head to tail or the other way around. it will be a doubly linkedlist of tuples
 * all inserts to linked_page_list have a flag to PRESERVE_ROOT_PAGE_ID
 * sort
   * it accepts record in the bplus_tree_bulkloading like interface
   * puts tuples in a page, sorts them and inserts it into a page_table
   * it will then merge adjacent runs until the page_table contains only 1 entry
 * Rtree will be supported
   * very similar to b+tree, n dimensional data can be searched, inserted, deleted, no least_keys_page_id required
   * splits and merges happen according to the minimal increase in interior node areas
   * searches walk down a tree, and maintain a stack, releasing locks only if only 1 entry is to be scannd in the interior node, next, prev and get_curr are supported, leafs may be acquired with write locks
   * inserts walk down only 1 path of the tree, trying to minimize the increased area
   * deleted walk down like a search would, and since we maintain a stack, a delete can be performed, which will destroy the stack releasing all locks
   * you need to define a rtree_tuple_definitions, that also has a function to get the hyper_rectangle for any of the records, which defines the minimum area hyper rectangle that the record falls into, as expected that allows you to store n dimensional lines, points etc.
   * hyper rectangle is an n dimensional rectangle.
   * all interior nodes store a hyper rectangle and a corresponding page_id, and atleast 2 entries must fit on a page, else rttd contruction fails. yet you can have any number of dimensions.
   * you can also specify any numeral datatype for dimension, as long as it is supported by the TupleStore.
   * need to think about how to calculate areas of the hyper rectangle with dimensions of different types, such that it fits a number and also does not violate precision requirements (getting areas is necessary for splitting and merging). think about using GNU MP for this purpose of getting area. BUT we can not store GNU MP number in the TupleStore. ALSO you can just use GNU MP for substractions of lower_bound and upper_bound to estimate splits and merges, but while constructing bounding boxes, you can revert to get_max(d0_lb_1, d0_lb_1), etc for computing the new bounding boxes.
   * fail insertions if the lower_bound and upper_bound of the get_hyper_rectangle do not follow <= comparison for any of the n dimensions.
   * build utility function to check that hyper rectangle does not have a negative dimension (i.e. lower_bound <= upper_bound), construct hyper_rectangle covering 2 or more hyper rectangles, and check if a hyper_rectangle intersects with another hyper_rectangle etc.
   * all queries take only hyper_rectangle keys for search and delete, while user takes a leaf record (this is why we need a function to build a hyper rectangle).
   * inserts and deletes can release page locks if it is deemed that split and merge would not propogate up the tree
   * accomodate any tuple that is atleast half the size of the leaf page, and interior page tuples would be fixed width with non NULL elements
   * keys will have a even count and all of numeral types, for ith dimension lower bound would be 2*i th key element and 2*i+1 will be upper bound, up to d dimentions (0 <= i < 2*d).
 * think about implementing more data structures like T-tree, Patricia Trie, etc

LEFT FOR LATER TASKS
DAM FEATURES (CONTIGUOUS ALOCATION and DEALLOCATION of pages) (Still think if you need this, with current hashtable design we have, we do not need this)
  * uint64_t allocate_contiguous_pages(uint64_t page_count), returning first page id of the allocated pages.
  * free_contiguous_pages will not be supported, since we need to be aware that the page must not be locked or waiting to be locked, while doing this, and so we would need a lot to do to undo in case if a page can not be freed, hence only allocate_contiguous_pages will be the only thing close to what we will support in dam api.
BPTTD FIX
  * failing on any malloc failures

** OPTIMIZATION (THIS MAY NEVER MAKE IT TO THE PROJECT)
 * implement redistribute keys functions for fixed length index_def, this will reduce propogation of merges, this task can be delayed to be done at the end
 * prefix key compression -> store prefix compression for var_strings (for internal nodes only), working in the following ways
    0  ->  "ABCD"            "ABCD"
    1  ->  "ABDEF"           "2DEF"
    2  ->  "ABDFG"           "3FG"
    3  ->  "ABDH"       ->   "3H"
    4  ->  "ADEA"            "1DEA"
    5  ->  "ADEF"            "3F"
    6  ->  "ADEGH"           "3GH"
    each var string except the first 1 stores itself OR its difference from the (same column) var string in the previous row
    the difference is stores as a number (suggesting the common characters from the previous var string) followed by the characters that are different.

    to differentiate the prefix number from the other characters, we will always store them in element_def's size_specifier_prefix_size number of bytes after an invalid unicode character "0xFF 0xFF".

    Algorithm to construct the string at ith index
    compute the length of the var string, that is 3 + "G" 1 + "H" 1 = 5
    bytes_to_read = 5 stack = ""
    now start iterating until bytes_to_read > 0
    i == 6 -> bytes_to_read = 3 stack = "HG"
    i == 5 -> bytes_to_read = 3 stack = "HG"
    i == 4 -> bytes_to_read = 1 stack = "HGED"
    i == 3 -> bytes_to_read = 1 stack = "HGED"
    i == 2 -> bytes_to_read = 1 stack = "HGED"
    i == 1 -> bytes_to_read = 1 stack = "HGED"
    i == 0 -> bytes_to_read = 0 stack = "HGEDA" -> reverse "ADEGH"

    stack = ""
    bytes_to_read = 5
    i = 6
    while(bytes_to_read > 0)
    {
      common_char_count, rest_of_string = get_column_from_ith_row(i);
      new_bytes_to_read = min(bytes_to_read, common_char_count);
      if(new_bytes_to_read > bytes_to_read)
      {
        for(int i = (new_bytes_to_read - bytes_to_read) - 1; i >= 0; i--)
          stack.push(rest_of_string[i]);
      }
      bytes_to_read = new_bytes_to_read;
    }
    return stack.reverse();

* think about future project (THIS WILL BE PROJECTS THAT WILL DEPEND ON THIS PROJECT)
 * think about how to do undo and redo logging
 * logical logging with physiological logging will allow us higher concurrency
 * mini transactions like that innodb can generate very large log records, which we may not want in memory
   * clubbing all physiological logs for a logical operation into a single buffer and log them only upon completion (with strict 2pl on the latches), can use large amount of memory for log buffer, but you can easily redo and undo it, it is never undone physiologically, only logically
 * How about we use logical mini transaction redo, composed of physiological logs, now we do physiological undo when logical operation is incomplete, and logical undo for other operations above. we may have to undo and undo in this case
