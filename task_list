
Stage 1
 * upon insert/delete perform compaction by checking the efficiency of the page at random (propbability 0.5) if the efficiency drops below 0.7

STAGE 2.1
 * set up test source for multi threaded insert delete and search operations

-- OPTIONAL TASKS BELOW (no to worry about it now) --

STAGE 3
 * implement the read logic into page_list and page_list_read_cursor
 * external_merge_sort for the page_list
 * building a bplus_tree on top of an external_merge_sorted page_list.
 * persistent storage using bufferpool library, providing a simple data_access_methods