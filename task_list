** PICKED TASKS

 * discrad sorted_packed_page from public api

ERROR HANDLING TASKS IN DAM
 * implement an error handling strategy to check the was_modified bit, in in-memory-data-store, and exit with error, if the page was modified and was_modified was not set.
 * print active read and write locks count, on the close call of unWALed_in_memory_data_store
 * free_pages_count is not being used, check why?

INMEMORY DAM FIXES AND DAM FEATURES
 * dam in release_lock(FREE_PAGE) -> allow the operation only if there is exactly only 1 thread, with reader and writer lock on the page, else fail to even release lock on the page
 * free_page must fail with an abort, if there are concurrent readers OR writers to the page, i.e. if a page is read or write locked (allow only 1 locker for the calling thread if FREE_PAGE is set for release_lock), while freeing a page.
 * dam add functionality (Still think if you need this, with current hashtable design we have, we do not need this)
  * uint64_t allocate_contiguous_pages(uint64_t page_count), returning first page id of the allocated pages.
  * free_contiguous_pages(uint64_t first_page_id, uint64_t page_count), instead of free_page -> to free n contiguous pages.

BPLUS_TREE_ITERATOR NEW FEATURES
 * handle case of bplus_tree_iterator pointing to empty leaf page, by going next or previous, until the curr_leaf_page has tuples.
 * allow inplace updates of non-key columns of the row (and only if the old and new value are of the same size), that the iterator is pointing to, only if the iterator is openned with leaf_lock_type == WRITE_LOCK
 * add a test case involving 2 threads, iterating with write locks in opposite directions (one stacked and another not-stacked) and modifying first bytes of the update to X or Y and print the results

UPDATE OPTIMIZATION
 * if the old_record is NULL, i.e. not found, then it is either a no-op (new_record = NULL) || an insert of new_record, so we can release parent page locks that can be released for split_insert, before calling the update inspector.

** OTHER DATABASE DATASTRUCTURE TASKS (VERY IMPORTANT FOR FUTURE OF PROJECT)
 * project and its makefile restructure, to put all bplus_tree files in the same directory
  * RM = rm -rf
  * MK = mkdir -p
  * both of above will easily do the job for nested directories, now we need to only call mkdir -p on creating an object
  * for objects add MK $(@D) to create its directory before creating the .o and .a files
  * for header restructure them from #include<bplus_tree.h> to #include<bplus_tree/bplus_tree.h>
 * hash_table, a linux page table like hashtable where each bucket points a linked_page_list, each working with PRESERVE_ROOT_PAGE_ID
   * each has table has 2 types of pages, HASH_ARRAY_PAGE and BUCKET_PAGE
   * BUCKET_PAGE are the ones that contain data, original tuples, with key and value (duplicate keys allowed)
   * HASH_ARRAY_PAGE are structured as tree, starting with level 0, and then on, like bplus tree
   * each entry in HASH_ARRAY_PAGE contain list of page_ids, each of page_id_width, pointing to another HASH_ARRAY_PAGE (when its level > 0) OR a BUCKET_PAGE (when its level = 0), all HASH_ARRAY_PAGE are identical.
   * root of the HASH_ARRAY_PAGE is never moved, root always stays at the same page, even on resizing.
   * If there are E entries in each of the HASH_ARRAY_PAGE, if the root page has level = n, then the hash table has E^(n+1) buckets.
   * If the root has only 1 entry at its first index, then the hash_table shrinks, by moving the contents of its new child to the root.
   * If any HASH_ARRAY_PAGE becomes all empty, then it is freed and an entry from its parent is discarded, shrinking the hash_table up the chain
   * HASH_ARRAY_PAGE for the children of other HASH_ARRAY_PAGE page are allocated, as and when required.
   * if the root HASH_ARRAY_PAGE if at level 0, yet is never to be disacrded, i.e. the capacity of hash_table has minimum value of E
   * BUCKET_PAGE are organized as doubly linkedlist, head of which is pointed to by the leaves (level 0) of HASH_ARRAY_PAGE.
   * Original data tuples on BUCKET_PAGE are never moved, allowing to build heap organized tables, on top of hash_table
   * when a BUCKET_PAGE is all empty it is freed, and removed from the linkedlist, if it is the last page in the BUCKET_PAGE linkedlist, then a NULL is written at the corresponding entry of the HASH_ARRAY_PAGE
   * tuples on BUCKET_PAGE can not move to different slots or other pages, once written they remain at the fixed slots, BUCKET_PAGE is reclaimed to be free, only when it becomes empty, on delete, we update the tuple with 0, and then discard_trailing_tomb_stones.
   * new tuples can be inserted at old slots.
 * linked_page_list push_tuple_at_head, push_tuple_at_tail, get_head_tuple, get_tail_tuple, pop_tuple_from_head and pop_tuple_from_tail as its access functions and an iterator from head to tail or the other way around. it will be a doubly linkedlist of tuples
 * all inserts to linked_page_list have a flag to PRESERVE_ROOT_PAGE_ID
 * sort that can be called on a linked_page_list or a hash_table
 * utility header function that reads page_type from common_page_header and helps get and set the next_page_id and prev_page_id
   * this can be used to build a generic iterator over linked list, bplus_tree leaf pages and interior pages
 * building a b+tree using a sorted linked_page_list, layer by layer
   * we will first ask for the sorted page double linked list, then build the bplus_tree level by level (level 0 being leaf page)
     * for building ith level of interior page, we copy the first tuple's key of all the lower level (i-1 level) pages, and build a singly linkedlist of interior pages composed of each index record pointing to the lower level page, we maintain only the heads of the 2 adjacent levels and a write iterator to the upper level and read iterator of the lower level.
     * since in the initial phase we are not storing the least_keys_page_id in the interior pages, we can use this interior page header field to link all pages in the same level as a singly linkedlist
     * for this we need to define an union {all_least_keys_page_id next_page_id}, to use the utility iterator to work.

** OPTIMIZATION
 * implement redistribute keys functions for fixed length index_def, this will reduce propogation of merges, this task can be delayed to be done at the end
 * prefix key compression -> store prefix compression for var_strings (for internal nodes only), working in the following ways
    0  ->  "ABCD"            "ABCD"
    1  ->  "ABDEF"           "2DEF"
    2  ->  "ABDFG"           "3FG"
    3  ->  "ABDH"       ->   "3H"
    4  ->  "ADEA"            "1DEA"
    5  ->  "ADEF"            "3F"
    6  ->  "ADEGH"           "3GH"
    each var string except the first 1 stores itself OR its difference from the (same column) var string in the previous row
    the difference is stores as a number (suggesting the common characters from the previous var string) followed by the characters that are different.

    to differentiate the prefix number from the other characters, we will always store them in element_def's size_specifier_prefix_size number of bytes after an invalid unicode character "0xFF 0xFF".

    Algorithm to construct the string at ith index
    compute the length of the var string, that is 3 + "G" 1 + "H" 1 = 5
    bytes_to_read = 5 stack = ""
    now start iterating until bytes_to_read > 0
    i == 6 -> bytes_to_read = 3 stack = "HG"
    i == 5 -> bytes_to_read = 3 stack = "HG"
    i == 4 -> bytes_to_read = 1 stack = "HGED"
    i == 3 -> bytes_to_read = 1 stack = "HGED"
    i == 2 -> bytes_to_read = 1 stack = "HGED"
    i == 1 -> bytes_to_read = 1 stack = "HGED"
    i == 0 -> bytes_to_read = 0 stack = "HGEDA" -> reverse "ADEGH"

    stack = ""
    bytes_to_read = 5
    i = 6
    while(bytes_to_read > 0)
    {
      common_char_count, rest_of_string = get_column_from_ith_row(i);
      new_bytes_to_read = min(bytes_to_read, common_char_count);
      if(new_bytes_to_read > bytes_to_read)
      {
        for(int i = (new_bytes_to_read - bytes_to_read) - 1; i >= 0; i--)
          stack.push(rest_of_string[i]);
      }
      bytes_to_read = new_bytes_to_read;
    }
    return stack.reverse();

* think about future project,
 * think about how to do undo and redo logging
 * logical logging with physiological logging will allow us higher concurrency
 * mini transactions like that innodb can generate very large log records, which we may not want in memory
   * clubbing all physiological logs for a logical operation into a single buffer and log them only upon completion (with strict 2pl on the latches), can use large amount of memory for log buffer, but you can easily redo and undo it, it is never undone physiologically, only logically
 * How about we use logical mini transaction redo, composed of physiological logs, now we do physiological undo when logical operation is incomplete, and logical undo for other operations above. we may have to undo and undo in this case
