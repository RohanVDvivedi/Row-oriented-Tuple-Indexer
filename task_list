** PICKED TASKS

* linked_page_list_iterator
  * int merge_dual_nodes_into_only_head(linked_page_list_iterator* lpli_p, const void* transaction_id, int* abort_erorr); -> that merges a dual node linked_page_list into a head only linked_page_list, making curr_page and curr_tuple_index, point to the same tuple
    * this can be used in discard_curr_page_if_empty, next and prev calls, when we want to merge dual_node_linked_page_list into a head_only_linked_page_list
  * int discard_if_points_to_empty_page with GO_NEXT/GO_PREV -> if the linked_page_list_iterator points to an empty page, then it is discarded
    * remove discards the empty page immediately, unless state == HEAD_ONLY, but does not actively attempt to merge.
    * to remove an empty page that is not head_page in a HEAD_ONLY_LPL, first take lock on next_page and prev_page, then remove empty page right from the middle, and then make the cursor point to the next or the prev.
      * if the head page becomes empty, then take lock on the next_page and next_next_page, then copy contents of the next_page to head_page and then remove the next_page from the middle, then go to next or prev tuple.
  * int next_linked_page_list_iterator(linked_page_list_iterator* lpli_p, const void* transaction_id, int* abort_error);
  * int prev_linked_page_list_iterator(linked_page_list_iterator* lpli_p, const void* transaction_id, int* abort_error);
    * as explained earlier next of the first tuple on the head page is last tuple on the tail page, and similarly next of tail page's last tuple is head page's first tuple -> This is due to circular nature of the linked_page_list
  * merging happens while going next or prev, when the tuple is write locked
    * first get lock on the next or prev page, and check if a merge of curr_page and the next/prev_page can be performed (explaining the case, when state = MANY_NODE)
    * you can not merge if the curr_page and the prev_page/next_page, becomes the pair head,tail or tail,head.
    * now, move contents of next_page or prev_page into the curr_page merging them in order, and then take lock on the next_next_page or prev_prev_page and remove next_page or prev_page from the linked_page_list and free it
    * no page can be empty so no need to do the above in a loop.
    * all in all if you call next(), you will either go to next page OR if possible copy contents of next_page into curr_page and then point to its tuples.
  * remove GO_NEXT/GO_PREV -> will only delete the tuple that we would be pointing to and then appropriately call next_* or prev_* function, to go to next or previous tuple of the deleted tuple. if the page becomes empty then it is discarded immidiately using the discard_if_points_to_empty_page function
  * int update_tuple and update_element -> to update a tuple or element the iterator is pointing to.
    * update_tuple takes EXPAND_TOWARDS_NEXT/EXPAND_TOWARDS_PREV as params and performs accordingly.
    * ensure that the new tuple does not exceed the max record size allowed, which is half of the space allotted to tuple on the page

** OTHER DATABASE DATASTRUCTURE TASKS (VERY IMPORTANT FOR FUTURE OF PROJECT)
 * bplus_tree bulk loading
   * bulk loading to accept bpttd_p, dam_p and pmm_p and allocate root page first
   * api to accept accept records, tuple by tuple
   * on build_call, generate interior pages
   * for building ith level of interior page, from the i-1th level, we copy the 1st row from the page with page id of the page, we will use the least_keys_page_id to link the level of the interior pages. for building tuple for iterior page level 1, we will use the suffix compression also to build the index tuple, while for other levels we will only use the same index tuple as in the first row of the interior page.
   * in the last pass, we will revisit all the interior pages using dfs and move the first row's page_id to least_keys_page_id and discard the first row.
 * hash_table, a page_table points a linked_page_list
   * with (duplicate keys allowed)
   * when a linked_page_list becomes all empty, then linked_page_list is destroyed and NULL_PAGE_ID is written to page_table
   * need to see how, to make bucket count dynamic, extendible hashing or linear hashing (I would prefer the later)
 * sort
   * it accepts record in the bplus_tree_bulkloading like interface
   * puts tuples in a page, sorts them and inserts it into a page_table
   * it will then merge adjacent runs until the page_table contains only 1 entry
 * Rtree will be supported
   * very similar to b+tree, n dimensional data can be searched, inserted, deleted, no least_keys_page_id required
   * splits and merges happen according to the minimal increase in interior node areas
   * searches walk down a tree, and maintain a stack, releasing locks only if only 1 entry is to be scannd in the interior node, next, prev and get_curr are supported, leafs may be acquired with write locks
   * inserts walk down only 1 path of the tree, trying to minimize the increased area
   * deleted walk down like a search would, and since we maintain a stack, a delete can be performed, which will destroy the stack releasing all locks
   * you need to define a rtree_tuple_definitions, that also has a function to get the hyper_rectangle for any of the records, which defines the minimum area hyper rectangle that the record falls into, as expected that allows you to store n dimensional lines, points etc.
   * hyper rectangle is an n dimensional rectangle.
   * all interior nodes store a hyper rectangle and a corresponding page_id, and atleast 2 entries must fit on a page, else rttd contruction fails. yet you can have any number of dimensions.
   * you can also specify any numeral datatype for dimension, as long as it is supported by the TupleStore.
   * need to think about how to calculate areas of the hyper rectangle with dimensions of different types, such that it fits a number and also does not violate precision requirements (getting areas is necessary for splitting and merging). think about using GNU MP for this purpose of getting area. BUT we can not store GNU MP number in the TupleStore. ALSO you can just use GNU MP for substractions of lower_bound and upper_bound to estimate splits and merges, but while constructing bounding boxes, you can revert to get_max(d0_lb_1, d0_lb_1), etc for computing the new bounding boxes.
   * fail insertions if the lower_bound and upper_bound of the get_hyper_rectangle do not follow <= comparison for any of the n dimensions.
   * build utility function to check that hyper rectangle does not have a negative dimension (i.e. lower_bound <= upper_bound), construct hyper_rectangle covering 2 or more hyper rectangles, and check if a hyper_rectangle intersects with another hyper_rectangle etc.
   * all queries take only hyper_rectangle keys for search and delete, while user takes a leaf record (this is why we need a function to build a hyper rectangle).
   * inserts and deletes can release page locks if it is deemed that split and merge would not propogate up the tree
   * accomodate any tuple that is atleast half the size of the leaf page, and interior page tuples would be fixed width with non NULL elements
   * keys will have a even count and all of numeral types, for ith dimension lower bound would be 2*i th key element and 2*i+1 will be upper bound, up to d dimentions (0 <= i < 2*d).
 * think about implementing more data structures like T-tree, Patricia Trie, etc

LEFT FOR LATER TASKS
DAM FEATURES (CONTIGUOUS ALOCATION and DEALLOCATION of pages) (Still think if you need this, with current hashtable design we have, we do not need this)
  * uint64_t allocate_contiguous_pages(uint64_t page_count), returning first page id of the allocated pages.
  * free_contiguous_pages will not be supported, since we need to be aware that the page must not be locked or waiting to be locked, while doing this, and so we would need a lot to do to undo in case if a page can not be freed, hence only allocate_contiguous_pages will be the only thing close to what we will support in dam api.
BPTTD FIX
  * failing on any malloc failures

** OPTIMIZATION (THIS MAY NEVER MAKE IT TO THE PROJECT)
 * implement redistribute keys functions for fixed length index_def, this will reduce propogation of merges, this task can be delayed to be done at the end
 * prefix key compression -> store prefix compression for var_strings (for internal nodes only), working in the following ways
    0  ->  "ABCD"            "ABCD"
    1  ->  "ABDEF"           "2DEF"
    2  ->  "ABDFG"           "3FG"
    3  ->  "ABDH"       ->   "3H"
    4  ->  "ADEA"            "1DEA"
    5  ->  "ADEF"            "3F"
    6  ->  "ADEGH"           "3GH"
    each var string except the first 1 stores itself OR its difference from the (same column) var string in the previous row
    the difference is stores as a number (suggesting the common characters from the previous var string) followed by the characters that are different.

    to differentiate the prefix number from the other characters, we will always store them in element_def's size_specifier_prefix_size number of bytes after an invalid unicode character "0xFF 0xFF".

    Algorithm to construct the string at ith index
    compute the length of the var string, that is 3 + "G" 1 + "H" 1 = 5
    bytes_to_read = 5 stack = ""
    now start iterating until bytes_to_read > 0
    i == 6 -> bytes_to_read = 3 stack = "HG"
    i == 5 -> bytes_to_read = 3 stack = "HG"
    i == 4 -> bytes_to_read = 1 stack = "HGED"
    i == 3 -> bytes_to_read = 1 stack = "HGED"
    i == 2 -> bytes_to_read = 1 stack = "HGED"
    i == 1 -> bytes_to_read = 1 stack = "HGED"
    i == 0 -> bytes_to_read = 0 stack = "HGEDA" -> reverse "ADEGH"

    stack = ""
    bytes_to_read = 5
    i = 6
    while(bytes_to_read > 0)
    {
      common_char_count, rest_of_string = get_column_from_ith_row(i);
      new_bytes_to_read = min(bytes_to_read, common_char_count);
      if(new_bytes_to_read > bytes_to_read)
      {
        for(int i = (new_bytes_to_read - bytes_to_read) - 1; i >= 0; i--)
          stack.push(rest_of_string[i]);
      }
      bytes_to_read = new_bytes_to_read;
    }
    return stack.reverse();

* think about future project (THIS WILL BE PROJECTS THAT WILL DEPEND ON THIS PROJECT)
 * think about how to do undo and redo logging
 * logical logging with physiological logging will allow us higher concurrency
 * mini transactions like that innodb can generate very large log records, which we may not want in memory
   * clubbing all physiological logs for a logical operation into a single buffer and log them only upon completion (with strict 2pl on the latches), can use large amount of memory for log buffer, but you can easily redo and undo it, it is never undone physiologically, only logically
 * How about we use logical mini transaction redo, composed of physiological logs, now we do physiological undo when logical operation is incomplete, and logical undo for other operations above. we may have to undo and undo in this case
