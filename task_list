
Stage 1
 * upon insert/delete perform compaction by checking the efficiency of the page at random (propbability 0.5) if the efficiency drops below 0.7

STAGE 2.1
 * set up test source for multi threaded insert delete and search operations

-- OPTIONAL TASKS BELOW (no to worry about it now) --

STAGE 3
 * implement page_list_write_handle
 	* it stores prev_page, page_list and curr_page pointers
 * api - insert_page_after_curr_page, insert_page_before_curr_page, delete_curr_page, get_curr_page

STAGE 4
 * external_merge_sort for the page_list
 * building a bplus_tree on top of an external_merge_sorted page_list.
 * persistent storage using bufferpool library, providing a simple data_access_methods